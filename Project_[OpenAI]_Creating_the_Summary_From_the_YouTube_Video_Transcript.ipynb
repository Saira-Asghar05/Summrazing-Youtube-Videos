{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pvZtcjOy1jbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae860aa-4e47-4278-d496-90b0989cc5ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.5.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from youtube-transcript-api) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->youtube-transcript-api) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->youtube-transcript-api) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->youtube-transcript-api) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->youtube-transcript-api) (2.10)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai==0.26.4\n",
            "  Downloading openai-0.26.4.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai==0.26.4) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai==0.26.4) (3.8.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai==0.26.4) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.26.4) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.26.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.26.4) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai==0.26.4) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai==0.26.4) (6.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.4-py3-none-any.whl size=67744 sha256=7c6501af967dc01074608fd08d1751034844c5aca6e0741a8e8fe8b326dbd9fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/d8/4e/268f029bd3277c1dd9e8781a0e0296e0a63822665bfa2429fc\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-dotenv==0.21.1\n",
            "  Downloading python_dotenv-0.21.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.21.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: youtube_transcript_api==0.5.0 in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from youtube_transcript_api==0.5.0) (2.25.1)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->youtube_transcript_api==0.5.0) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->youtube_transcript_api==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->youtube_transcript_api==0.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->youtube_transcript_api==0.5.0) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.8/dist-packages (0.21.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (57.4.0)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-67.3.3-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "cvxpy 1.2.3 requires setuptools<=64.0.2, but you have setuptools 67.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-23.0.1 setuptools-67.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube-transcript-api\n",
        "!pip install openai==0.26.4\n",
        "!pip install python-dotenv==0.21.1\n",
        "!pip install youtube_transcript_api==0.5.0\n",
        "!pip install python-dotenv\n",
        "!python -m pip install -U pip setuptools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import pandas as pd\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "import os\n",
        "import datetime\n"
      ],
      "metadata": {
        "id": "XAz-rzGA1wmF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_list = YouTubeTranscriptApi.list_transcripts('nE2skSRWTTs')\n",
        "transcript_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9ZPRvhs144R",
        "outputId": "a1b8a12f-b10c-4145-d17a-5c87a4494335"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<youtube_transcript_api._transcripts.TranscriptList at 0x7fbe79ac5fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch the english transcript\n",
        "transcript = transcript_list.find_transcript(['en'])\n",
        "transcript_fetched = transcript.fetch()"
      ],
      "metadata": {
        "id": "65pTb7VM1_4U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting and accessing OpenAI API key as an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# Load OpenAI API key from the environment\n",
        "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "# print(openai_api_key)"
      ],
      "metadata": {
        "id": "v2dngTwu-aO-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = ''\n",
        "# Creating chunks of the YouTube Transcript\n",
        "def split_transcript_by_seconds(transcript_fetched, seconds):\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_time = None\n",
        "    \n",
        "    for line_data in transcript_fetched:\n",
        "        line_time = datetime.timedelta(seconds=line_data['start'])\n",
        "        \n",
        "        if current_time is None:\n",
        "            current_time = line_time\n",
        "            \n",
        "        if (line_time - current_time).total_seconds() > seconds:\n",
        "            chunks.append(current_chunk)\n",
        "            current_chunk = []\n",
        "            current_time = line_time\n",
        "        \n",
        "        current_chunk.append(line_data['text'])\n",
        "    \n",
        "    chunks.append(current_chunk)\n",
        "    return chunks\n",
        "# 300 are the seconds (5 minutes), The whole transcript will be divided into 5 minute chunks a\n",
        "chunks = split_transcript_by_seconds(transcript_fetched, 300)\n",
        "\n",
        "# Each chunk being fed to the Gpt-003 model\n",
        "for i in range(len(chunks)):\n",
        "  transcript_texted = \"\".join(chunks[i])\n",
        "  \n",
        "  import openai\n",
        "  openai.api_key = openai_api_key\n",
        "  prompt = \"Please summarize the following YouTube transcript, without your remarks like 'In this transcript'. Keep the summary consistant with the previous chunk. Use names of people used in video instead of calling them speakers:\\n\" + transcript_texted\n",
        "  try:\n",
        "      # Send the request to the OpenAI API\n",
        "      response = openai.Completion.create(\n",
        "          model=\"text-davinci-003\",\n",
        "          prompt=prompt,\n",
        "          temperature=0.7,\n",
        "          max_tokens=150,\n",
        "          top_p=1,\n",
        "          frequency_penalty=0,\n",
        "          presence_penalty=0\n",
        "      )\n",
        "\n",
        "      # Get the summary from the response\n",
        "      summary = response.choices[0].text\n",
        "      result += summary   # adding the summary of each chunk together to form a single string text.\n",
        "  except openai.error.OpenAIError as error:\n",
        "      # Handle the error\n",
        "      print(f\"OpenAI API Error: {error}\")\n",
        "print(\"Summarized Transcript: \",result)\n",
        "#writing the final summarized string to the file\n",
        "filename = \"output.txt\"\n",
        "with open(filename, 'w') as file:\n",
        "    file.write(result)"
      ],
      "metadata": {
        "id": "OnY_Rqe8UMM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa7bbbe-240b-4dea-a662-627fd1a59f8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summarized Transcript:   1.7so this is the final result of thisexecutor chain and this is the type ofthing that we can build using line chain.\n",
            "\n",
            "Lang chain is an NLP framework that allows developers to quickly build apps using large language models. In this video, the core components of Lang chain are introduced, such as prompt templates, large language models, agents, and memory. An example of an Asian executor chain is shown, which uses a query to find who Olivia Wilde's boyfriend is and then calculates his age to the 0.23 power. The result is Harry Styles who is 28 years old, with 1.7 as the final result of the executor chain.so what we're going to do is we're justgoing to copy the model name and we'llcome over here and we'll put that modelname in here so this is what we'll beusing to generate our large languagemodels\n",
            "\n",
            "Lancer demonstrates how to use Langchain to generate text using Hugging Face's large language models. He explains the use of short-term and long-term memory in large language models, and how to use the conversation buffer memory to maintain a conversation with a chatbot. He also explains how to use data augmented generation to access external data sources and keep the model up-to-date. He then demonstrates how to use the Google Flair T5 XL model from Hugging Face Hub to generate text.other services like Google Colab orAWS Lambda you may need to pass in theAPI key directly in your code so ifyou're not running on your localmachine you may need to do that so Inthis transcript, Aaron explains how to use an OpenAI model to answer questions. He sets the randomness of the model to low and creates a template with a question and answer. He then uses the template to ask a question and prints the result. He suggests testing multiple questions together and explains how to use the OpenAI library and API key. He further explains that OpenAI can handle multiple questions at once, but the model didn't really listen to him. Lastly, he explains the need to pass in the API key directly in the code\n",
            "\n",
            "Azure used the openAI API version, the text DaVinci 003 model, and a prompt to generate an answer to a question about the Green Bay Packers winning the Super Bowl. The model gave an accurate answer. Eugene Cernan was incorrectly identified as the 12th person to walk on the moon, but the Apollo 17 mission in December 1972 was correctly identified. In addition, when given a question about how tall someone is if they are 6 foot 4 inches, the model provided an accurate answer in centimeters. Finally, the model correctly stated that a blade of grass does not have eyes.\n"
          ]
        }
      ]
    }
  ]
}